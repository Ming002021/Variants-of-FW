Using Phase I method to get a starting point: 
Describing a summary of the model: 
Termination Status: OPTIMAL 
Primal Status: FEASIBLE_POINT 
Message from the solver: Solution is optimal
Objective Value: 0.0

The value of the objective function of the starting solution is 0.0 

The  Pairwise Frank-Wolfe Algorithm in Atom Version with Phase I is Starting:

This is the iteration 1: 
I am solving an LP problem over feasible region to get the Toward direction now:
Describing a summary of the model: 
Termination Status: OPTIMAL 
Primal Status: FEASIBLE_POINT 
Message from the solver: Solution is optimal

I am solving an LP problem over D to get the Away direction now:

The gap is 514.0 in this iteration
Step-size gained is 1.0

In iteration 1, the objective function value of the solution gained is -650.5


This is the iteration 2: 
I am solving an LP problem over feasible region to get the Toward direction now:
Describing a summary of the model: 
Termination Status: OPTIMAL 
Primal Status: FEASIBLE_POINT 
Message from the solver: Solution is optimal

I am solving an LP problem over D to get the Away direction now:

The gap is 1400.0 in this iteration
Step-size gained is 1.0

In iteration 2, the objective function value of the solution gained is -1679.5


This is the iteration 3: 
I am solving an LP problem over feasible region to get the Toward direction now:
Describing a summary of the model: 
Termination Status: OPTIMAL 
Primal Status: FEASIBLE_POINT 
Message from the solver: Solution is optimal

I am solving an LP problem over D to get the Away direction now:

The gap is 814.0 in this iteration
Step-size gained is 0.7146619841966637

In iteration 3, the objective function value of the solution gained is -1970.3674275680419


This is the iteration 4: 
I am solving an LP problem over feasible region to get the Toward direction now:
Describing a summary of the model: 
Termination Status: OPTIMAL 
Primal Status: FEASIBLE_POINT 
Message from the solver: Solution is optimal

I am solving an LP problem over D to get the Away direction now:

The gap is 417.5074626865671 in this iteration
Step-size gained is 0.2853380158033363

In iteration 4, the objective function value of the solution gained is -2085.223744932827


This is the iteration 5: 
I am solving an LP problem over feasible region to get the Toward direction now:
Describing a summary of the model: 
Termination Status: OPTIMAL 
Primal Status: FEASIBLE_POINT 
Message from the solver: Solution is optimal

I am solving an LP problem over D to get the Away direction now:

The gap is 312.8905259376823 in this iteration
Step-size gained is 0.587786872091157

In iteration 5, the objective function value of the solution gained is -2213.7472923378336


This is the iteration 6: 
I am solving an LP problem over feasible region to get the Toward direction now:
Describing a summary of the model: 
Termination Status: OPTIMAL 
Primal Status: FEASIBLE_POINT 
Message from the solver: Solution is optimal

I am solving an LP problem over D to get the Away direction now:

The gap is 137.17679750262516 in this iteration
Step-size gained is 0.2853380158033363

In iteration 6, the objective function value of the solution gained is -2249.687483121234


This is the iteration 7: 
I am solving an LP problem over feasible region to get the Toward direction now:
Describing a summary of the model: 
Termination Status: OPTIMAL 
Primal Status: FEASIBLE_POINT 
Message from the solver: Solution is optimal

I am solving an LP problem over D to get the Away direction now:

The gap is 74.13602245729668 in this iteration
Step-size gained is 0.12687511210550673

In iteration 7, the objective function value of the solution gained is -2274.9982873462727


This is the iteration 8: 
I am solving an LP problem over feasible region to get the Toward direction now:
Describing a summary of the model: 
Termination Status: OPTIMAL 
Primal Status: FEASIBLE_POINT 
Message from the solver: Solution is optimal

I am solving an LP problem over D to get the Away direction now:

The gap is 78.7640765106412 in this iteration
Step-size gained is 0.587786872091157

In iteration 8, the objective function value of the solution gained is -2350.145983290313


This is the iteration 9: 
I am solving an LP problem over feasible region to get the Toward direction now:
Describing a summary of the model: 
Termination Status: OPTIMAL 
Primal Status: FEASIBLE_POINT 
Message from the solver: Solution is optimal

I am solving an LP problem over D to get the Away direction now:

The gap is 87.06661055268296 in this iteration
Step-size gained is 0.2853380158033363

In iteration 9, the objective function value of the solution gained is -2408.05781815318


This is the iteration 10: 
I am solving an LP problem over feasible region to get the Toward direction now:
Describing a summary of the model: 
Termination Status: OPTIMAL 
Primal Status: FEASIBLE_POINT 
Message from the solver: Solution is optimal

I am solving an LP problem over D to get the Away direction now:

The gap is 30.02257208243692 in this iteration
Step-size gained is 0.12687511210550673

In iteration 10, the objective function value of the solution gained is -2417.6235137324284


This is the iteration 11: 
I am solving an LP problem over feasible region to get the Toward direction now:
Describing a summary of the model: 
Termination Status: OPTIMAL 
Primal Status: FEASIBLE_POINT 
Message from the solver: Solution is optimal

I am solving an LP problem over D to get the Away direction now:

The gap is 21.29494011659028 in this iteration
Step-size gained is 0.587786872091157

In iteration 11, the objective function value of the solution gained is -2436.5


This is the iteration 12: 
I am solving an LP problem over feasible region to get the Toward direction now:
Describing a summary of the model: 
Termination Status: OPTIMAL 
Primal Status: FEASIBLE_POINT 
Message from the solver: Solution is optimal

I am solving an LP problem over D to get the Away direction now:

The gap is 0.0 in this iteration

Termination condition with respect to epsilon is satisfied with iteration 12 and final value -2436.5


